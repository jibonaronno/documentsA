<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head profile="http://gmpg.org/xfn/11">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="distribution" content="global" />
<meta name="robots" content="follow, all" />
<meta name="language" content="en, sv" />

<title> Gustavo Duarte</title>
<meta name="generator" content="WordPress 3.5.1" />
<!-- leave this for stats please -->
<!-- ukey="24FE583D" -->
<link rel="Shortcut Icon" href="http://duartes.org/gustavo/blog/wp-content/themes/dropshadow-2column/images/favicon.ico" type="image/x-icon" />
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://duartes.org/gustavo/blog/feed" />
<link rel="alternate" type="text/xml" title="RSS .92" href="http://duartes.org/gustavo/blog/feed/rss" />
<link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="http://duartes.org/gustavo/blog/feed/atom" />
<link rel="pingback" href="http://duartes.org/gustavo/blog/xmlrpc.php" />
	<link rel='archives' title='December 2010' href='http://duartes.org/gustavo/blog/post/2010/12' />
	<link rel='archives' title='February 2009' href='http://duartes.org/gustavo/blog/post/2009/02' />
	<link rel='archives' title='January 2009' href='http://duartes.org/gustavo/blog/post/2009/01' />
	<link rel='archives' title='December 2008' href='http://duartes.org/gustavo/blog/post/2008/12' />
	<link rel='archives' title='November 2008' href='http://duartes.org/gustavo/blog/post/2008/11' />
	<link rel='archives' title='October 2008' href='http://duartes.org/gustavo/blog/post/2008/10' />
	<link rel='archives' title='August 2008' href='http://duartes.org/gustavo/blog/post/2008/08' />
	<link rel='archives' title='July 2008' href='http://duartes.org/gustavo/blog/post/2008/07' />
	<link rel='archives' title='June 2008' href='http://duartes.org/gustavo/blog/post/2008/06' />
	<link rel='archives' title='May 2008' href='http://duartes.org/gustavo/blog/post/2008/05' />
	<link rel='archives' title='April 2008' href='http://duartes.org/gustavo/blog/post/2008/04' />
	<link rel='archives' title='March 2008' href='http://duartes.org/gustavo/blog/post/2008/03' />
	<link rel='archives' title='February 2008' href='http://duartes.org/gustavo/blog/post/2008/02' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://duartes.org/gustavo/blog/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://duartes.org/gustavo/blog/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 3.5.1" />
<style type="text/css" media="screen">
<!-- @import url( http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/style.css ); -->
</style>
</head>

<body>

<div id="header">

<div class="headerleft">
	<a href="http://duartes.org/gustavo/blog/">Gustavo Duarte</a><br />
	<b>Software, computers, and business.</b>
	</div>

<div class="headerright">
	<ul>
		<li><a href="http://duartes.org/gustavo/blog">Home</a></li>
		<li><a href="http://duartes.org/gustavo/blog/about">About</a></li>
		<li><a href="http://duartes.org/gustavo/blog/articles">Articles</a></li>
		<li><a href="http://feeds.feedburner.com/GustavoDuarte">Subscribe</a></li>
	</ul>
</div>

</div>

<div id="content">

	<div id="contentleft">
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing" rel="bookmark">Added Best Of Page, Back to Writing</a></h1>
		<p>I have created a <a href="/gustavo/blog/best-of">Best Of</a> page with links to the better posts I have written in the blog. This should help people who want to read all of the Software Illustrated posts. I expect to write new posts this next year, covering more internals stuff as well as other programming topics.</p>
<p>To everybody who wrote during my hiatus with encouragement and wondering if I was dead, a huge thank you, and no. To folks who asked technical questions, I am sorry I haven&#8217;t replied, but between work and play I have had <b>zero</b> time available.</p>
<p>Speaking of which, I&#8217;ll be in Summit County between Jan 2nd and Feb 20th, riding at Breck, Keystone, ABasin, and Vail. If you&#8217;d like to ride or ski together, <a href="mailto://gustavo@duartes.org">drop me a line</a>.</p>
<p>I hope you have a wonderful 2011!<br />
<center><img src="http://duartes.org/gustavo/blog/wp-content/uploads/2010/12/riding.jpg" alt="Riding at Copper" title="Riding at Copper" width="300" height="400" /></center></p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>December 31, 2010 at 1:06 am | Filed Under <a href="http://duartes.org/gustavo/blog/category/meta" title="View all posts in Meta" rel="category tag">Meta</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing#comments" title="Comment on Added Best Of Page, Back to Writing">53 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing"
    dc:identifier="http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing"
    dc:title="Added Best Of Page, Back to Writing"
    trackback:ping="http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files" rel="bookmark">Page Cache, the Affair Between Memory and Files</a></h1>
		<p>Previously we looked at how the kernel <a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory">manages virtual memory</a> for a user process, but files and I/O were left out. This post covers the important and often misunderstood relationship between files and memory and its consequences for performance.</p>
<p>Two serious problems must be solved by the OS when it comes to files. The first one is the mind-blowing slowness of hard drives, and <a href="http://duartes.org/gustavo/blog/post/what-your-computer-does-while-you-wait">disk seeks in particular</a>, relative to memory. The second is the need to load file contents in physical memory once and <em>share</em> the contents among programs. If you use <a href="http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx">Process Explorer</a> to poke at Windows processes, you&#8217;ll see there are ~15MB worth of common DLLs loaded in every process. My Windows box right now is running 100 processes, so without sharing I&#8217;d be using up to ~1.5 GB of physical RAM <em>just for common DLLs</em>. No good. Likewise, nearly all Linux programs need ld.so and libc, plus other common libraries.</p>
<p>Happily, both problems can be dealt with in one shot: the <strong>page cache</strong>, where the kernel stores page-sized chunks of files. To illustrate the page cache, I&#8217;ll conjure a Linux program named <strong>render</strong>, which opens file <strong>scene.dat</strong> and reads it 512 bytes at a time, storing the file contents into a heap-allocated block. The first read goes like this:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/readFromPageCache.png" alt="Reading and the page cache"/></p>
<p>After 12KB have been read, <tt>render</tt>&#8216;s heap and the relevant page frames look thus:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/nonMappedFileRead.png" alt="Non-mapped file read"/></p>
<p>This looks innocent enough, but there&#8217;s a lot going on. First, even though this program uses regular <tt>read</tt> calls, three 4KB page frames are now in the page cache storing part of <tt>scene.dat</tt>. People are sometimes surprised by this, but <strong>all regular file I/O happens through the page cache</strong>. In x86 Linux, the kernel thinks of a file as a sequence of 4KB chunks. If you read a single byte from a file, the whole 4KB chunk containing the byte you asked for is read from disk and placed into the page cache. This makes sense because sustained disk throughput is pretty good and programs normally read more than just a few bytes from a file region. The page cache knows the position of each 4KB chunk within the file, depicted above as #0, #1, etc. Windows uses 256KB <strong>views</strong> analogous to pages in the Linux page cache.</p>
<p>Sadly, in a regular file read the kernel must copy the contents of the page cache into a user buffer, which not only takes cpu time and hurts the <a href="http://duartes.org/gustavo/blog/intel-cpu-caches">cpu caches</a>, but also <strong>wastes physical memory with duplicate data</strong>. As per the diagram above, the <tt>scene.dat</tt> contents are stored twice, and each instance of the program would store the contents an additional time. We&#8217;ve mitigated the disk latency problem but failed miserably at everything else. <strong>Memory-mapped files</strong> are the way out of this madness:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/mappedFileRead.png" alt="Mapped file read"/></p>
<p>When you use file mapping, the kernel maps your program&#8217;s virtual pages directly onto the page cache. This can deliver a significant performance boost: <a href="http://www.amazon.com/Windows-Programming-Addison-Wesley-Microsoft-Technology/dp/0321256190/">Windows System Programming</a> reports run time improvements of 30% and up relative to regular file reads, while similar figures are reported for Linux and Solaris in <a href="http://www.amazon.com/Programming-Environment-Addison-Wesley-Professional-Computing/dp/0321525949/">Advanced Programming in the Unix Environment</a>. You might also save large amounts of physical memory, depending on the nature of your application.</p>
<p>As always with performance, <a href="http://duartes.org/gustavo/blog/performance-is-a-science">measurement is everything</a>, but memory mapping earns its keep in a programmer&#8217;s toolbox. The API is pretty nice too, it allows you to access a file as bytes in memory and does not require your soul and code readability in exchange for its benefits. Mind your <a href="http://duartes.org/gustavo/blog/anatomy-of-a-program-in-memory">address space</a> and experiment with <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/mmap.2.html">mmap</a> in Unix-like systems, <a href="http://msdn.microsoft.com/en-us/library/aa366537(VS.85).aspx">CreateFileMapping</a> in Windows, or the many wrappers available in high level languages. When you map a file its contents are not brought into memory all at once, but rather on demand via <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2678">page faults</a>. The fault handler <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2436">maps your virtual pages</a> onto the page cache after <a href="http://lxr.linux.no/linux+v2.6.28/mm/filemap.c#L1424">obtaining</a> a page frame with the needed file contents. This involves disk I/O if the contents weren&#8217;t cached to begin with.</p>
<p>Now for a pop quiz. Imagine that the last instance of our <tt>render</tt> program exits. Would the pages storing <em>scene.dat</em> in the page cache be freed immediately? People often think so, but that would be a bad idea. When you think about it, it is very common for us to create a file in one program, exit, then use the file in a second program. The page cache must handle that case. When you think <em>more</em> about it, why should the kernel <em>ever</em> get rid of page cache contents? Remember that disk is 5 orders of magnitude slower than RAM, hence a page cache hit is a huge win. So long as there&#8217;s enough free physical memory, the cache should be kept full. It is therefore <em>not</em> dependent on a particular process, but rather it&#8217;s a system-wide resource. If you run <tt>render</tt> a week from now and <tt>scene.dat</tt> is still cached, bonus! This is why the kernel cache size climbs steadily until it hits a ceiling. It&#8217;s not because the OS is garbage and hogs your RAM, it&#8217;s actually good behavior because in a way free physical memory is a waste. Better use as much of the stuff for caching as possible.</p>
<p>Due to the page cache architecture, when a program calls <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/write.2.html">write()</a> bytes are simply copied to the page cache and the page is marked dirty. Disk I/O normally does <strong>not</strong> happen immediately, thus your program doesn&#8217;t block waiting for the disk. On the downside, if the computer crashes your writes will never make it, hence critical files like database transaction logs must be <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/fsync.2.html">fsync()</a>ed (though one must still worry about drive controller caches, oy!). Reads, on the other hand, normally block your program until the data is available. Kernels employ eager loading to mitigate this problem, an example of which is <strong>read ahead</strong> where the kernel preloads a few pages into the page cache in anticipation of your reads. You can help the kernel tune its eager loading behavior by providing hints on whether you plan to read a file sequentially or randomly (see <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/madvise.2.html">madvise()</a>, <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/readahead.2.html">readahead()</a>, <a href="http://msdn.microsoft.com/en-us/library/aa363858(VS.85).aspx#caching_behavior">Windows cache hints</a>). Linux <a href="http://lxr.linux.no/linux+v2.6.28/mm/filemap.c#L1424">does read-ahead</a> for memory-mapped files, but I&#8217;m not sure about Windows. Finally, it&#8217;s possible to bypass the page cache using <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/open.2.html">O_DIRECT</a> in Linux or <a href="http://msdn.microsoft.com/en-us/library/cc644950(VS.85).aspx">NO_BUFFERING</a> in Windows, something database software often does.</p>
<p>A file mapping may be <strong>private</strong> or <strong>shared</strong>. This refers only to <strong>updates</strong> made to the contents in memory: in a private mapping the updates are not committed to disk or made visible to other processes, whereas in a shared mapping they are. Kernels use the <strong>copy on write</strong> mechanism, enabled by page table entries, to implement private mappings. In the example below, both <tt>render</tt> and another program called <tt>render3d</tt> (am I creative or what?) have mapped <tt>scene.dat</tt> privately. <tt>Render</tt> then writes to its virtual memory area that maps the file:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/copyOnWrite.png" alt="The Copy-On-Write mechanism"/></p>
<p>The read-only page table entries shown above do <em>not</em> mean the mapping is read only, they&#8217;re merely a kernel trick to share physical memory until the last possible moment. You can see how &#8216;private&#8217; is a bit of a misnomer until you remember it only applies to updates. A consequence of this design is that a virtual page that maps a file privately sees changes done to the file by other programs <em>as long as the page has only been read from</em>. Once copy-on-write is done, changes by others are no longer seen. This behavior is not guaranteed by the kernel, but it&#8217;s what you get in x86 and makes sense from an API perspective. By contrast, a shared mapping is simply mapped onto the page cache and that&#8217;s it. Updates are visible to other processes and end up in the disk. Finally, if the mapping above were read-only, page faults would trigger a segmentation fault instead of copy on write.</p>
<p>Dynamically loaded libraries are brought into your program&#8217;s address space via file mapping. There&#8217;s nothing magical about it, it&#8217;s the same private file mapping available to you via regular APIs. Below is an example showing part of the address spaces from two running instances of the file-mapping <tt>render</tt> program, along with physical memory, to tie together many of the concepts we&#8217;ve seen.</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/virtualToPhysicalMapping.png" alt="Mapping virtual memory to physical memory"/></p>
<p>This concludes our 3-part series on memory fundamentals. I hope the series was useful and provided you with a good mental model of these OS topics. Next week there&#8217;s one more post on memory usage figures, and then it&#8217;s time for a change of air. Maybe some Web 2.0 gossip or something. <img src='http://duartes.org/gustavo/blog/wp-includes/images/smilies/icon_wink.gif' alt=';)' class='wp-smiley' /> </p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>February 10, 2009 at 11:20 pm | Filed Under <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>, <a href="http://duartes.org/gustavo/blog/category/linux" title="View all posts in Linux" rel="category tag">Linux</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files#comments" title="Comment on Page Cache, the Affair Between Memory and Files">61 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files"
    dc:identifier="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files"
    dc:title="Page Cache, the Affair Between Memory and Files"
    trackback:ping="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/the-thing-king" rel="bookmark">The Thing King</a></h1>
		<p>I hope the <a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory">previous post</a> explained virtual memory adequately, but I must admit I held back a much better explanation, which I first saw in <a href="http://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298/">Expert C Programming</a>. It wasn&#8217;t written by the book&#8217;s author, Peter van der Linden, but rather by Jeff Berryman in 1972. Here goes:</p>
<p><b>The Thing King and the Paging Game</b></p>
<p>This note is a formal non-working paper of the Project MAC Computer Systems Research Division. It should be reproduced and distributed wherever levity is lacking, and may be referenced at your own risk in other publications.</p>
<h4>Rules</h4>
<ol>
<li>Each player gets several million things.</li>
<li>Things are kept in crates that hold 4096 things each. Things in the same crate are called crate-mates.</li>
<li>Crates are stored either in the workshop or the warehouses. The workshop is almost always too small to hold all the crates.</li>
<li>There is only one workshop but there may be several warehouses. Everybody shares them.</li>
<li>Each thing has its own thing number.</li>
<li>What you do with a thing is to zark it. Everybody takes turns zarking.</li>
<li>You can only zark your things, not anybody else&#8217;s.</li>
<li>Things can only be zarked when they are in the workshop.</li>
<li>Only the Thing King knows whether a thing is in the workshop or in a warehouse.</li>
<li>The longer a thing goes without being zarked, the grubbier it is said to become.</li>
<li>The way you get things is to ask the Thing King. He only gives out things by the crateful. This is to keep the royal overhead down.</li>
<li>The way you zark a thing is to give its thing number. If you give the number of a thing that happens to be in a workshop it gets zarked right away. If it is in a warehouse, the Thing King packs the crate containing your thing back into the workshop. If there is no room in the workshop, he first finds the grubbiest crate in the workshop, whether it be yours or somebody else&#8217;s, and packs it off with all its crate-mates to a warehouse. In its place he puts the crate containing your thing. Your thing then gets zarked and you never know that it wasn&#8217;t in the workshop all along.</li>
<li>Each player&#8217;s stock of things have the same numbers as everybody else&#8217;s. The Thing King always knows who owns what thing and whose turn it is, so you can&#8217;t ever accidentally zark somebody else&#8217;s thing even if it has the same thing number as one of yours.</li>
</ol>
<h4>Notes</h4>
<ol>
<li>Traditionally, the Thing King sits at a large, segmented table and is attended to by pages (the so-called &#8220;table pages&#8221;) whose job it is to help the king remember where all the things are and who they belong to.</li>
<li>One consequence of Rule 13 is that everybody&#8217;s thing numbers will be similar from game to game, regardless of the number of players.</li>
<li>The Thing King has a few things of his own, some of which move back and forth between workshop and warehouse just like anybody else&#8217;s, but some of which are just too heavy to move out of the workshop.</li>
<li>With the given set of rules, oft-zarked things tend to get kept mostly in the workshop while little-zarked things stay mostly in a warehouse. This is efficient stock control.</li>
</ol>
<p><strong>Long Live the Thing King!</strong></p>
<p><b>Update:</b> Alex pointed out the difficulties of measuring grubbiness in a comment below.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>February 4, 2009 at 10:12 am | Filed Under <a href="http://duartes.org/gustavo/blog/category/culture" title="View all posts in Culture" rel="category tag">Culture</a>, <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/the-thing-king#comments" title="Comment on The Thing King">15 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/the-thing-king"
    dc:identifier="http://duartes.org/gustavo/blog/post/the-thing-king"
    dc:title="The Thing King"
    trackback:ping="http://duartes.org/gustavo/blog/post/the-thing-king/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory" rel="bookmark">How The Kernel Manages Your Memory</a></h1>
		<p>After examining the <a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory">virtual address layout</a> of a process, we turn to the kernel and its mechanisms for managing user memory. Here is gonzo again:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/mm_struct.png" alt="Linux kernel mm_struct"/></p>
<p>Linux processes are implemented in the kernel as instances of <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/sched.h#L1075">task_struct</a>, the process descriptor. The <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/sched.h#L1129">mm</a> field in task_struct points to the <strong>memory descriptor</strong>, <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L173">mm_struct</a>, which is an executive summary of a program&#8217;s memory. It stores the start and end of memory segments as shown above, the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L197">number</a> of physical memory pages used by the process (<strong>rss</strong> stands for Resident Set Size), the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L206">amount</a> of virtual address space used, and other tidbits. Within the memory descriptor we also find the two work horses for managing program memory: the set of <strong>virtual memory areas</strong> and the <strong>page tables</strong>. Gonzo&#8217;s memory areas are shown below:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/memoryDescriptorAndMemoryAreas.png" alt="Kernel memory descriptor and memory areas"/></p>
<p>Each virtual memory area (VMA) is a contiguous range of virtual addresses; these areas never overlap. An instance of <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L99">vm_area_struct</a> fully describes a memory area, including its start and end addresses, <a href="http://lxr.linux.no/linux+v2.6.28/include/linux/mm.h#L76">flags</a> to determine access rights and behaviors, and the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L150">vm_file</a> field to specify which file is being mapped by the area, if any. A VMA that does not map a file is <strong>anonymous</strong>. Each memory segment above (<em>e.g.</em>, heap, stack) corresponds to a single VMA, with the exception of the memory mapping segment. This is not a requirement, though it is usual in x86 machines. VMAs do not care which segment they are in.</p>
<p>A program&#8217;s VMAs are stored in its memory descriptor both as a linked list in the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L174">mmap</a> field, ordered by starting virtual address, and as a <a href="http://en.wikipedia.org/wiki/Red_black_tree">red-black tree</a> rooted at the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L175">mm_rb</a> field. The red-black tree allows the kernel to search quickly for the memory area covering a given virtual address. When you read file <tt>/proc/pid_of_process/maps</tt>, the kernel is simply going through the linked list of VMAs for the process and <a href="http://lxr.linux.no/linux+v2.6.28.1/fs/proc/task_mmu.c#L201">printing each one</a>.</p>
<p>In Windows, the <a href="http://www.nirsoft.net/kernel_struct/vista/EPROCESS.html">EPROCESS</a> block is roughly a mix of task_struct and mm_struct. The Windows analog to a VMA is the Virtual Address Descriptor, or <a href="http://www.nirsoft.net/kernel_struct/vista/MMVAD.html">VAD</a>; they are stored in an <a href="http://en.wikipedia.org/wiki/AVL_tree">AVL tree</a>. You know what the funniest thing about Windows and Linux is? It&#8217;s the little differences.</p>
<p>The 4GB virtual address space is divided into <strong>pages</strong>. x86 processors in 32-bit mode support page sizes of 4KB, 2MB, and 4MB. Both Linux and Windows map the user portion of the virtual address space using 4KB pages. Bytes 0-4095 fall in page 0, bytes 4096-8191 fall in page 1, and so on. The size of a VMA <em>must be a multiple of page size</em>. Here&#8217;s 3GB of user space in 4KB pages:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/pagedVirtualSpace.png" alt="4KB Pages Virtual User Space"/></p>
<p>The processor consults <strong>page tables</strong> to translate a virtual address into a physical memory address. Each process has its own set of page tables; whenever a process switch occurs, page tables for user space are switched as well. Linux stores a pointer to a process&#8217; page tables in the <a href="http://lxr.linux.no/linux+v2.6.28.1/include/linux/mm_types.h#L185">pgd</a> field of the memory descriptor. To each virtual page there corresponds one <strong>page table entry</strong> (PTE) in the page tables, which in regular x86 paging is a simple 4-byte record shown below:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/x86PageTableEntry4KB.png" alt="x86 Page Table Entry (PTE) for 4KB page"/></p>
<p>Linux has functions to <a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/include/asm/pgtable.h#L173">read</a> and <a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/include/asm/pgtable.h#L230">set</a> each flag in a PTE. Bit P tells the processor whether the virtual page is <strong>present</strong> in physical memory. If clear (equal to 0), accessing the page triggers a page fault. Keep in mind that when this bit is zero, <strong>the kernel can do whatever it pleases</strong> with the remaining fields. The R/W flag stands for read/write; if clear, the page is read-only. Flag U/S stands for user/supervisor; if clear, then the page can only be accessed by the kernel. These flags are used to implement the read-only memory and protected kernel space we saw before.</p>
<p>Bits D and A are for <strong>dirty</strong> and <strong>accessed</strong>. A dirty page has had a write, while an accessed page has had a write or read. Both flags are sticky: the processor only sets them, they must be cleared by the kernel. Finally, the PTE stores the starting physical address that corresponds to this page, aligned to 4KB. This naive-looking field is the source of some pain, for it limits addressable physical memory to <a href="http://www.google.com/search?hl=en&amp;q=2^20+*+2^12+bytes+in+GB">4 GB</a>. The other PTE fields are for another day, as is Physical Address Extension.</p>
<p>A virtual page is the unit of memory protection because all of its bytes share the U/S and R/W flags. However, the same physical memory could be mapped by different pages, possibly with different protection flags. Notice that execute permissions are nowhere to be seen in the PTE. This is why classic x86 paging allows code on the stack to be executed, making it easier to exploit stack buffer overflows (it&#8217;s still possible to exploit non-executable stacks using <a href="http://en.wikipedia.org/wiki/Return-to-libc_attack">return-to-libc</a> and other techniques). This lack of a PTE no-execute flag illustrates a broader fact: permission flags in a VMA may or may not translate cleanly into hardware protection. The kernel does what it can, but ultimately the architecture limits what is possible.</p>
<p>Virtual memory doesn&#8217;t store anything, it simply <em>maps</em> a program&#8217;s address space onto the underlying physical memory, which is accessed by the processor as a large block called the <strong>physical address space</strong>. While memory operations on the bus are <a href="http://duartes.org/gustavo/blog/post/getting-physical-with-memory">somewhat involved</a>, we can ignore that here and assume that physical addresses range from zero to the top of available memory in one-byte increments. This physical address space is broken down by the kernel into <strong>page frames</strong>. The processor doesn&#8217;t know or care about frames, yet they are crucial to the kernel because <strong>the page frame is the unit of physical memory management.</strong> Both Linux and Windows use 4KB page frames in 32-bit mode; here is an example of a machine with 2GB of RAM:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/physicalAddressSpace.png" alt="Physical Address Space"/></p>
<p>In Linux each page frame is tracked by a <a href="http://lxr.linux.no/linux+v2.6.28/include/linux/mm_types.h#L32">descriptor</a> and <a href="http://lxr.linux.no/linux+v2.6.28/include/linux/page-flags.h#L14">several flags</a>. Together these descriptors track the entire physical memory in the computer; the precise state of each page frame is always known. Physical memory is managed with the <a href="http://en.wikipedia.org/wiki/Buddy_memory_allocation">buddy memory allocation</a> technique, hence a page frame is <strong>free</strong> if it&#8217;s available for allocation via the buddy system. An allocated page frame might be <strong>anonymous</strong>, holding program data, or it might be in the <strong>page cache</strong>, holding data stored in a file or block device. There are other exotic page frame uses, but leave them alone for now. Windows has an analogous Page Frame Number (PFN) database to track physical memory.</p>
<p>Let&#8217;s put together virtual memory areas, page table entries and page frames to understand how this all works. Below is an example of a user heap:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/heapMapped.png" alt="Physical Address Space"/></p>
<p>Blue rectangles represent pages in the VMA range, while arrows represent page table entries mapping pages onto page frames. Some virtual pages lack arrows; this means their corresponding PTEs have the <strong>Present</strong> flag clear. This could be because the pages have never been touched or because their contents have been swapped out. In either case access to these pages will lead to page faults, even though they are within the VMA. It may seem strange for the VMA and the page tables to disagree, yet this often happens.</p>
<p>A VMA is like a contract between your program and the kernel. You ask for something to be done (memory allocated, a file mapped, etc.), the kernel says &#8220;sure&#8221;, and it creates or updates the appropriate VMA. But <em>it does not</em> actually honor the request right away, it waits until a page fault happens to do real work. The kernel is a lazy, deceitful sack of scum; this is the fundamental principle of virtual memory. It applies in most situations, some familiar and some surprising, but the rule is that VMAs record what has been <em>agreed upon</em>, while PTEs reflect what has <em>actually been done</em> by the lazy kernel. These two data structures together manage a program&#8217;s memory; both play a role in resolving page faults, freeing memory, swapping memory out, and so on. Let&#8217;s take the simple case of memory allocation:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/heapAllocation.png" alt="Example of demand paging and memory allocation"/></p>
<p>When the program asks for more memory via the <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/brk.2.html">brk()</a> system call, the kernel simply <a href="http://lxr.linux.no/linux+v2.6.28.1/mm/mmap.c#L2050">updates</a> the heap VMA and calls it good. No page frames are actually allocated at this point and the new pages are not present in physical memory. Once the program tries to access the pages, the processor page faults and <a href="http://lxr.linux.no/linux+v2.6.28/arch/x86/mm/fault.c#L583">do_page_fault()</a> is called. It <a href="http://lxr.linux.no/linux+v2.6.28/arch/x86/mm/fault.c#L692">searches</a> for the VMA covering the faulted virtual address using <a href="http://lxr.linux.no/linux+v2.6.28/mm/mmap.c#L1466">find_vma()</a>. If found, the permissions on the VMA are also checked against the attempted access (read or write). If there&#8217;s no suitable VMA, no contract covers the attempted memory access and the process is punished by Segmentation Fault.</p>
<p>When a VMA is <a href="http://lxr.linux.no/linux+v2.6.28/arch/x86/mm/fault.c#L711">found</a> the kernel must <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2653">handle</a> the fault by looking at the PTE contents and the type of VMA. In our case, the PTE shows the page is <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2674">not present</a>. In fact, our PTE is completely blank (all zeros), which in Linux means the virtual page has never been mapped. Since this is an anonymous VMA, we have a purely RAM affair that must be handled by <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2681">do_anonymous_page()</a>, which allocates a page frame and makes a PTE to map the faulted virtual page onto the freshly allocated frame.</p>
<p>Things could have been different. The PTE for a swapped out page, for example, has 0 in the Present flag but is not blank. Instead, it stores the swap location holding the page contents, which must be read from disk and loaded into a page frame by <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2280">do_swap_page()</a> in what is called a <a href="http://lxr.linux.no/linux+v2.6.28/mm/memory.c#L2316">major fault</a>.</p>
<p>This concludes the first half of our tour through the kernel&#8217;s user memory management. In the next post, we&#8217;ll throw files into the mix to build a complete picture of memory fundamentals, including consequences for performance.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>February 3, 2009 at 11:35 pm | Filed Under <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>, <a href="http://duartes.org/gustavo/blog/category/linux" title="View all posts in Linux" rel="category tag">Linux</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory#comments" title="Comment on How The Kernel Manages Your Memory">117 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory"
    dc:identifier="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory"
    dc:title="How The Kernel Manages Your Memory"
    trackback:ping="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog" rel="bookmark">Quick Note on Diagrams and the Blog</a></h1>
		<p>People often ask me what tool I use to make the diagrams in my <a href="http://duartes.org/gustavo/blog/category/software-illustrated">Software Illustrated</a> posts. I use MS Visio 2007. It has a &#8216;themes&#8217; feature that allows you to set fill and line options that apply to all the shapes in a diagram, making it faster to produce decent looking things. It still takes a surprising amount of work to get good pictures, but overall I&#8217;m pretty happy.</p>
<p>Also, I have tried to use colors to convey <em>meaning</em>. They&#8217;re not just for pretty. For example, memory colors follow these conventions across all diagrams:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/memoryColorsLegend.png" alt="Legend for memory colors"/></p>
<p>These colors hold from the <a href="http://duartes.org/gustavo/blog/post/memory-translation-and-segmentation">earliest post</a> about memory to <a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory">the latest</a>. This convention is why the post about <a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches">Intel CPU caches</a> shows a blue index for the virtually indexed L1 cache. So far I&#8217;ve written a lot about kernel and x86 internals, but that&#8217;s sort of a coincidence. I&#8217;m a generalist, not an OS guy; there&#8217;s a wide range of CS topics I hope to write about. (All this internals talk though made me want to write Linux kernel code again. I might look for some subsystem or driver to work on. What&#8217;s that sleep supression pill again?)</p>
<p>Finally, in the next couple of months I plan to change my blog template. The new one will have a hand-maintained &#8216;Archive by Topic&#8217; page to serve as a coherent index to all posts, plus other usability improvements. I hate the current site as far as that goes. I can handle the logic and markup, but if anyone out there is interested in doing a small design/CSS job on this blog, please <a href="mailto://gustavo-web@duartes.org">drop me a line</a>. I also have a quick question. Many people access the site via iPhones and other mobile devices. How does image width impact you? Would it be painful if diagrams were wider than their current 700-pixel limit? I&#8217;d appreciate input on this and suggestions in general. Thanks! I&#8217;m off to check out the <a href="http://php.meetup.com/382/calendar/9386636/?a=nr1p_grp">Denver LAMP meetup</a>. Here&#8217;s a <a href="http://www.youtube.com/watch?v=ljgAnV8iNXE">good song</a> if you&#8217;re bored.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 28, 2009 at 6:21 pm | Filed Under <a href="http://duartes.org/gustavo/blog/category/meta" title="View all posts in Meta" rel="category tag">Meta</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog#comments" title="Comment on Quick Note on Diagrams and the Blog">19 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog"
    dc:identifier="http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog"
    dc:title="Quick Note on Diagrams and the Blog"
    trackback:ping="http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory" rel="bookmark">Anatomy of a Program in Memory</a></h1>
		<p>Memory management is the heart of operating systems; it is crucial for both programming and system administration. In the next few posts I&#8217;ll cover memory with an eye towards practical aspects, but without shying away from internals. While the concepts are generic, examples are mostly from Linux and Windows on 32-bit x86. This first post describes how programs are laid out in memory.</p>
<p>Each process in a multi-tasking OS runs in its own memory sandbox. This sandbox is the <strong>virtual address space</strong>, which in 32-bit mode is <strong>always a 4GB block of memory addresses</strong>. These virtual addresses are mapped to physical memory by <strong>page tables</strong>, which are maintained by the operating system kernel and consulted by the processor. Each process has its own set of page tables, but there is a catch. Once virtual addresses are enabled, they apply to <em>all software</em> running in the machine, <em>including the kernel itself</em>. Thus a portion of the virtual address space must be reserved to the kernel:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/kernelUserMemorySplit.png" alt="Kernel/User Memory Split"/></p>
<p>This does <strong>not</strong> mean the kernel uses that much physical memory, only that it has that portion of address space available to map whatever physical memory it wishes. Kernel space is flagged in the page tables as exclusive to <a href="http://duartes.org/gustavo/blog/post/cpu-rings-privilege-and-protection">privileged code</a> (ring 2 or lower), hence a page fault is triggered if user-mode programs try to touch it. In Linux, kernel space is constantly present and maps the same physical memory in all processes. Kernel code and data are always addressable, ready to handle interrupts or system calls at any time. By contrast, the mapping for the user-mode portion of the address space changes whenever a process switch happens:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/virtualMemoryInProcessSwitch.png" alt="Process Switch Effects on Virtual Memory"/></p>
<p>Blue regions represent virtual addresses that are mapped to physical memory, whereas white regions are unmapped. In the example above, Firefox has used far more of its virtual address space due to its legendary memory hunger. The distinct bands in the address space correspond to <strong>memory segments</strong> like the heap, stack, and so on. Keep in mind these segments are simply a range of memory addresses and <em>have nothing to do</em> with <a href="http://duartes.org/gustavo/blog/post/memory-translation-and-segmentation">Intel-style segments</a>. Anyway, here is the standard segment layout in a Linux process:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/linuxFlexibleAddressSpaceLayout.png" alt="Flexible Process Address Space Layout In Linux"/></p>
<p>When computing was happy and safe and cuddly, the starting virtual addresses for the segments shown above were <strong>exactly the same</strong> for nearly every process in a machine. This made it easy to exploit security vulnerabilities remotely. An exploit often needs to reference absolute memory locations: an address on the stack, the address for a library function, etc. Remote attackers must choose this location blindly, counting on the fact that address spaces are all the same. When they are, people get pwned. Thus address space randomization has become popular. Linux randomizes the <a href="http://lxr.linux.no/linux+v2.6.28.1/fs/binfmt_elf.c#L542">stack</a>,  <a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/mm/mmap.c#L84">memory mapping segment</a>, and <a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/kernel/process_32.c#L729">heap</a> by adding offsets to their starting addresses. Unfortunately the 32-bit address space is pretty tight, leaving little room for randomization and <a href="http://www.stanford.edu/~blp/papers/asrandom.pdf">hampering its effectiveness</a>.</p>
<p>The topmost segment in the process address space is the stack, which stores local variables and function parameters in most programming languages. Calling a method or function pushes a new <strong>stack frame</strong> onto the stack. The stack frame is destroyed when the function returns. This simple design, possible because the data obeys strict <a href="http://en.wikipedia.org/wiki/Lifo">LIFO</a> order, means that no complex data structure is needed to track stack contents &#8211; a simple pointer to the top of the stack will do. Pushing and popping are thus very fast and deterministic. Also, the constant reuse of stack regions tends to keep active stack memory in the <a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches">cpu caches</a>, speeding up access. Each thread in a process gets its own stack.</p>
<p>It is possible to exhaust the area mapping the stack by pushing more data than it can fit. This triggers a page fault that is handled in Linux by <a href="http://lxr.linux.no/linux+v2.6.28/mm/mmap.c#L1716">expand_stack()</a>, which in turn calls <a href="http://lxr.linux.no/linux+v2.6.28/mm/mmap.c#L1544">acct_stack_growth()</a> to check whether it&#8217;s appropriate to grow the stack. If the stack size is below <tt>RLIMIT_STACK</tt> (usually 8MB), then normally the stack grows and the program continues merrily, unaware of what just happened. This is the normal mechanism whereby stack size adjusts to demand. However, if the maximum stack size has been reached, we have a <strong>stack overflow</strong> and the program receives a Segmentation Fault. While the mapped stack area expands to meet demand, it does not shrink back when the stack gets smaller. Like the federal budget, it only expands.</p>
<p>Dynamic stack growth is the <a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/mm/fault.c#L692">only situation</a> in which access to an unmapped memory region, shown in white above, might be valid. Any other access to unmapped memory triggers a page fault that results in a Segmentation Fault. Some mapped areas are read-only, hence write attempts to these areas also lead to segfaults.</p>
<p>Below the stack, we have the memory mapping segment. Here the kernel maps contents of files directly to memory. Any application can ask for such a mapping via the Linux <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/mmap.2.html">mmap()</a> system call (<a href="http://lxr.linux.no/linux+v2.6.28.1/arch/x86/kernel/sys_i386_32.c#L27">implementation</a>) or <a href="http://msdn.microsoft.com/en-us/library/aa366537(VS.85).aspx">CreateFileMapping()</a> / <a href="http://msdn.microsoft.com/en-us/library/aa366761(VS.85).aspx">MapViewOfFile()</a> in Windows. Memory mapping is a convenient and high-performance way to do file I/O, so it is used for loading dynamic libraries. It is also possible to create an <strong>anonymous memory mapping</strong> that does not correspond to any files, being used instead for program data. In Linux, if you request a large block of memory via <a href="http://www.kernel.org/doc/man-pages/online/pages/man3/malloc.3.html">malloc()</a>, the C library will create such an anonymous mapping instead of using heap memory. &#8216;Large&#8217; means larger than <tt>MMAP_THRESHOLD</tt> bytes, 128 kB by default and adjustable via <a href="http://www.kernel.org/doc/man-pages/online/pages/man3/undocumented.3.html">mallopt()</a>.</p>
<p>Speaking of the heap, it comes next in our plunge into address space. The heap provides runtime memory allocation, like the stack, meant for data that must outlive the function doing the allocation, unlike the stack. Most languages provide heap management to programs. Satisfying memory requests is thus a joint affair between the language runtime and the kernel. In C, the interface to heap allocation is <a href="http://www.kernel.org/doc/man-pages/online/pages/man3/malloc.3.html">malloc()</a> and friends, whereas in a garbage-collected language like C# the interface is the <tt>new</tt> keyword.</p>
<p>If there is enough space in the heap to satisfy a memory request, it can be handled by the language runtime without kernel involvement. Otherwise the heap is enlarged via the <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/brk.2.html">brk()</a> system call (<a href="http://lxr.linux.no/linux+v2.6.28.1/mm/mmap.c#L248">implementation</a>) to make room for the requested block. Heap management is <a href="http://g.oswego.edu/dl/html/malloc.html">complex</a>, requiring sophisticated algorithms that strive for speed and efficient memory usage in the face of our programs&#8217; chaotic allocation patterns. The time needed to service a heap request can vary substantially. Real-time systems have <a href="http://rtportal.upv.es/rtmalloc/">special-purpose allocators</a> to deal with this problem. Heaps also become <em>fragmented</em>, shown below:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/fragmentedHeap.png" alt="Fragmented Heap"/></p>
<p>Finally, we get to the lowest segments of memory: BSS, data, and program text. Both BSS and data store contents for static (global) variables in C. The difference is that BSS stores the contents of <em>uninitialized</em> static variables, whose values are not set by the programmer in source code. The BSS memory area is anonymous: it does not map any file. If you say <tt>static int cntActiveUsers</tt>, the contents of <tt>cntActiveUsers</tt> live in the BSS.</p>
<p>The data segment, on the other hand, holds the contents for static variables initialized in source code. This memory area <strong>is not anonymous</strong>. It maps the part of the program&#8217;s binary image that contains the initial static values given in source code. So if you say <tt>static int cntWorkerBees = 10</tt>, the contents of cntWorkerBees live in the data segment and start out as 10. Even though the data segment maps a file, it is a <strong>private memory mapping</strong>, which means that updates to memory are not reflected in the underlying file. This must be the case, otherwise assignments to global variables would change your on-disk binary image. Inconceivable!</p>
<p>The data example in the diagram is trickier because it uses a pointer. In that case, the <em>contents</em> of pointer <tt>gonzo</tt> &#8211; a 4-byte memory address &#8211; live in the data segment. The actual string it points to does not, however. The string lives in the <strong>text</strong> segment, which is read-only and stores all of your code in addition to tidbits like string literals. The text segment also maps your binary file in memory, but writes to this area earn your program a Segmentation Fault. This helps prevent pointer bugs, though not as effectively as avoiding C in the first place. Here&#8217;s a diagram showing these segments and our example variables:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/mappingBinaryImage.png" alt="ELF Binary Image Mapped Into Memory"/></p>
<p>You can examine the memory areas in a Linux process by reading the file <tt>/proc/pid_of_process/maps</tt>. Keep in mind that a segment may contain many areas. For example, each memory mapped file normally has its own area in the mmap segment, and dynamic libraries have extra areas similar to BSS and data. The next post will clarify what &#8216;area&#8217; really means. Also, sometimes people say &#8220;data segment&#8221; meaning all of data + bss + heap.</p>
<p>You can examine binary images using the <a href="http://manpages.ubuntu.com/manpages/intrepid/en/man1/nm.1.html">nm</a> and <a href="http://manpages.ubuntu.com/manpages/intrepid/en/man1/objdump.1.html">objdump</a> commands to display symbols, their addresses, segments, and so on. Finally, the virtual address layout described above is the &#8220;flexible&#8221; layout in Linux, which has been the default for a few years. It assumes that we have a value for <tt>RLIMIT_STACK</tt>. When that&#8217;s not the case, Linux reverts back to the &#8220;classic&#8221; layout shown below:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/linuxClassicAddressSpaceLayout.png" alt="Classic Process Address Space Layout In Linux"/></p>
<p>That&#8217;s it for virtual address space layout. The next post discusses how the kernel keeps track of these memory areas. Coming up we&#8217;ll look at memory mapping, how file reading and writing ties into all this and what memory usage figures mean.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 27, 2009 at 12:34 am | Filed Under <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>, <a href="http://duartes.org/gustavo/blog/category/linux" title="View all posts in Linux" rel="category tag">Linux</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory#comments" title="Comment on Anatomy of a Program in Memory">179 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory"
    dc:identifier="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory"
    dc:title="Anatomy of a Program in Memory"
    trackback:ping="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/getting-physical-with-memory" rel="bookmark">Getting Physical With Memory</a></h1>
		<p>When trying to understand complex systems, you can often learn a lot by stripping away abstractions and looking at their lowest levels. In that spirit we take a look at memory and I/O ports in their simplest and most fundamental level: the interface between the processor and bus. These details underlie higher level topics like thread synchronization and the need for the Core i7. Also, since I&#8217;m a programmer I ignore things EE people care about. Here&#8217;s our friend the Core 2 again:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/physicalMemoryAccess.png" alt="Physical Memory Access"/></p>
<p>A Core 2 processor has 775 pins, about half of which only provide power and carry no data. Once you group the pins by functionality, the physical interface to the processor is surprisingly simple. The diagram shows the key pins involved in a memory or I/O port operation: address lines, data pins, and request pins. These operations take place in the context of a <strong>transaction</strong> on the front side bus. FSB transactions go through 5 phases: arbitration, request, snoop, response, and data. Throughout these phases, different roles are played by the components on the FSB, which are called <strong>agents</strong>. Normally the agents are all the processors plus the northbridge.</p>
<p>We only look at the <strong>request phase</strong> in this post, in which 2 packets are output by the <strong>request agent</strong>, who is usually a processor. Here are the juiciest bits of the first packet, output by the address and request pins:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/fsbRequestPhasePacketA.png" alt="FSB Request Phase, Packet A"/></p>
<p>The address lines output the starting physical memory address for the transaction. We have 33 bits but they are interpreted as bits 35-3 of an address in which bits 2-0 are zero. Hence we have a 36-bit address, aligned to 8 bytes, for a total of <a href="http://www.google.com/search?hl=en&amp;q=2^36+bytes">64GB</a> addressable physical memory. This has been the case since the Pentium Pro. The request pins specify what type of transaction is being initiated; in I/O requests the address pins specify an I/O port rather than a memory address. After the first packet is output, the same pins transmit a second packet in the subsequent bus clock cycle:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/fsbRequestPhasePacketB.png" alt="FSB Request Phase, Packet B"/></p>
<p>The attribute signals are interesting: they reflect the 5 types of memory caching behavior available in Intel processors. By putting this information on the FSB, the request agent lets other processors know how this transaction affects their caches, and how the memory controller (northbridge) should behave. The processor determines the type of a given memory region mainly by looking at page tables, which are maintained by the kernel.</p>
<p>Typically kernels treat <strong>all RAM memory as write-back</strong>, which yields the best performance. In write-back mode the unit of memory access is the <a href="http://duartes.org/gustavo/blog/intel-cpu-caches">cache line</a>, 64 bytes in the Core 2. If a program reads a single byte in memory, the processor loads the whole cache line that contains that byte into the L2 and L1 caches. When a program <em>writes</em> to memory, the processor only modifies the line in the cache, but does <em>not</em> update main memory. Later, when it becomes necessary to post the modified line to the bus, the whole cache line is written at once. So most requests have 11 in their length field, for 64 bytes. Here&#8217;s a read example in which the data is not in the caches:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/memoryRead.png" alt="Memory Read Sequence Diagram"/></p>
<p>Some of the physical memory range in an Intel computer is <a href="http://duartes.org/gustavo/blog/post/motherboard-chipsets-memory-map">mapped to devices</a> like hard drives and network cards instead of actual RAM memory. This allows drivers to communicate with their devices by writing to and reading from memory. The kernel marks these memory regions as <strong>uncacheable</strong> in the page tables. Accesses to uncacheable memory regions are reproduced in the bus exactly as requested by a program or driver. Hence it&#8217;s possible to read or write single bytes, words, and so on. This is done via the byte enable mask in packet B above.</p>
<p>The primitives discussed here have many implications. For example:</p>
<ol>
<li>Performance-sensitive applications should try to pack data that is accessed together into the same cache line. Once the cache line is loaded, further reads are <a href="http://duartes.org/gustavo/blog/what-your-computer-does-while-you-wait">much faster</a> and extra RAM accesses are avoided.</li>
<li>Any memory access that falls within a single cache line is guaranteed to be atomic (assuming write-back memory). Such an access is serviced by the processor&#8217;s L1 cache and the data is read or written all at once; it cannot be affected halfway by other processors or threads. In particular, 32-bit and 64-bit operations that don&#8217;t cross cache line boundaries are atomic.</li>
<li>The front bus is shared by all agents, who must arbitrate for bus ownership before they can start a transaction. Moreover, all agents must listen to all transactions in order to maintain cache coherence. Thus bus contention becomes a severe problem as more cores and processors are added to Intel computers. The Core i7 solves this by having processors attached directly to memory and communicating in a point-to-point rather than broadcast fashion.</li>
</ol>
<p>These are the highlights of physical memory requests; the bus will surface again later in connection with locking, multi-threading, and cache coherence. The first time I saw FSB packet descriptions I had a huge &#8220;ahhh!&#8221; moment so I hope someone out there gets the same benefit. In the next post we&#8217;ll go back up the abstraction ladder to take a thorough look at virtual memory.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 15, 2009 at 11:15 am | Filed Under <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/getting-physical-with-memory#comments" title="Comment on Getting Physical With Memory">21 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/getting-physical-with-memory"
    dc:identifier="http://duartes.org/gustavo/blog/post/getting-physical-with-memory"
    dc:title="Getting Physical With Memory"
    trackback:ping="http://duartes.org/gustavo/blog/post/getting-physical-with-memory/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/programming-and-the-recession" rel="bookmark">Programming and the Recession</a></h1>
		<p>Back in April of last year I wrote about <a href="http://duartes.org/gustavo/blog/post/programming-language-jobs-and-trends">job numbers and trends</a> for programming languages. Since the newspapers tell me we&#8217;re all doomed to the soup line in the near future, I decided to compare the job numbers from last year to what we have now. Here&#8217;s the result:</p>
<p align="center">
<img src="http://static.duartes.org/img/blogPosts/jobLossesPerLanguage.png" alt="Job Losses Per Language" />
</p>
<p>All the numbers are from Dice.com, a rough measure to be sure, but useful nonetheless. The average decrease in the number of jobs was 40%, which seems pretty bad. I don&#8217;t know what the supply side looks like, but I imagine we now have more job seekers as well. Here is the % decrease in number of jobs, by programming language:</p>
<p align="center">
<img src="http://static.duartes.org/img/blogPosts/decreasePerLanguage.png" alt="% decrease per language" />
</p>
<p>Interesting to see how Python and Ruby held out a bit better, while Perl declined the most. But despite a rocky short term, the overall picture for software engineers <a href="http://www.bls.gov/oco/ocos267.htm">looks great</a> according to the US Bureau of Labor Statistics:</p>
<blockquote>
<ul style="margin-top:1em">
<li>Computer software engineers are one of the occupations projected to grow the fastest and add the most new jobs over the 2006-16 decade.</li>
<li>Excellent job prospects are expected for applicants with at least bachelors degree in computer engineering or computer science and with practical work experience. (&#8230;)</li>
</ul>
<p>
<strong>Employment change</strong>. Employment of computer software engineers is projected to increase by 38 percent over the 2006 to 2016 period, which is much faster than the average for all occupations. This occupation will generate about 324,000 new jobs over the projections decade, one of the largest employment increases of any occupation.
</p>
</blockquote>
<p>Not bad huh? Back in 2001 I pestered the BLS economists about this, asking them what they thought offshoring effects would be and so on. They came across as truly bullish on programming, which makes sense to me. The degree to which society depends on computers and programmers will only grow from here. Meanwhile, there is a natural barrier to entry when it comes to programming. When explaining the folly of projects that aim to develop software to replace programmers, Scott Westfall put it <a href="http://blog.slickedit.com/?p=255">this way</a>:</p>
<blockquote><p>
Programmers think more logically. Working through if-then-else conditions is a core capability for any programmer. While working with business teams on requirements, I have often run across cases the where same ability was lacking. (&#8230;) </p>
<p>Programmers have a superior ability to analyze problems and come up with solutions. They excel at analyzing preconditions, sequences of events, and outcomes. Certainly, this is a key skill in programming, but it is also useful in troubleshooting and business case analysis.(&#8230;)</p>
<p>While people typically think of programmers as coders, whose main talent lies in writing the arcane syntax of programming languages. I think that their main talent lies in their ability to analyze, troubleshoot, and solve problems. Code is just the physical manifestation that culminates the thought process of the programmer.(&#8230;)
</p></blockquote>
<p>I see two major consequences of this. First, the supply of programmers is constrained because the work requires a fair bit of aptitude that cannot be replaced by training. Second, programmers have a lot of professional options due to these skills, which further hurts supply. I think the economics is in our favor and we&#8217;re still <a href="http://duartes.org/gustavo/blog/post/lucky-to-be-a-programmer">lucky to be programmers</a>, though we must be careful during the recession. What do you say? How does it look out there?</p>
<p><strong>Update:</strong> you guys have brought up a number of points about the &#8216;methodology&#8217; behind the Dice.com job numbers. For example, there are seasonal effects on hiring, so it would have been better to compare the two same months. Also, there may be a drop in the usage of Dice.com itself, rather than a drop in the number of available jobs. Besides, many good companies and applicants have turned away from Dice because of poor results for both sides. That is all true. I look at the Dice.com figures as a rough metric. But as a large tech jobs site I think Dice reflects the market at large, albeit imperfectly. A drop of 40% is significant enough that I find it likely it&#8217;s a real phenomenon.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 14, 2009 at 2:26 am | Filed Under <a href="http://duartes.org/gustavo/blog/category/business" title="View all posts in Business" rel="category tag">Business</a>, <a href="http://duartes.org/gustavo/blog/category/programming" title="View all posts in Programming" rel="category tag">Programming</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/programming-and-the-recession#comments" title="Comment on Programming and the Recession">27 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/programming-and-the-recession"
    dc:identifier="http://duartes.org/gustavo/blog/post/programming-and-the-recession"
    dc:title="Programming and the Recession"
    trackback:ping="http://duartes.org/gustavo/blog/post/programming-and-the-recession/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire" rel="bookmark">Daddy, why does it smell like fire?</a></h1>
		<p>So on Sunday morning my daughter runs up to me and asks me why it &#8220;smells like fire.&#8221; </p>
<p>&#8220;FIRE?&#8221; </p>
<p>&#8220;Yes fire, weee, let&#8217;s find the fire! Fire fire fire, woohoo!&#8221; </p>
<p>Should I stop reading my book? Run? Panic? Let the house burn down, collect the insurance money, <a href="http://www.youtube.com/watch?v=3BW7rLWQhTA">take a hippie name and start a farm</a>?</p>
<p>After a couple of minutes we narrow down the fire smell to my office. Oh shit! I start smelling the backs of my computers, the power supply fans. &#8220;GOOD LORD NO!!! NOT MY COMPUTER, NO NO, BURN MY WIFE&#8217;S COMPUTER INSTEAD!!!&#8221;</p>
<p>Alas, it was my computer. But at least not the main computer, so I count my blessings. At this point I don&#8217;t even know <i>what</i> the hell burned, though the computer is dead (turns on, PSU fan comes up, nothing else). I open up the bugger and start looking for some blackened component but find none. <i>No</i> signs of damage. I start smelling all over the motherboard, hard drives, processor, snorting up all sorts of carcinogens and shortening my life by at least a couple years, but it&#8217;s all uniformly stinky as far as my nose can tell.</p>
<p>I always buy good power supplies, this one was a ~500W <a href="http://www.newegg.com/Product/ProductList.aspx?Submit=ENE&#038;N=2010320058%2050011154&#038;name=HIPER">HIPER</a>, sure looked high quality to me. You know, HIPER quality. I&#8217;ve never had anything like this before, so not sure what to think. I wonder if all components are damaged. Is this a PSU failure?</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 12, 2009 at 11:18 pm | Filed Under <a href="http://duartes.org/gustavo/blog/category/personal" title="View all posts in Personal" rel="category tag">Personal</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire#comments" title="Comment on Daddy, why does it smell like fire?">28 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire"
    dc:identifier="http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire"
    dc:title="Daddy, why does it smell like fire?"
    trackback:ping="http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
		
		<!-- begin write_post -->
		<h1><a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches" rel="bookmark">Cache: a place for concealment and safekeeping</a></h1>
		<p>This post shows briefly how CPU caches are organized in modern Intel processors. Cache discussions often lack concrete examples, obfuscating the simple concepts involved. Or maybe my pretty little head is slow. At any rate, here&#8217;s half the story on how a Core 2 L1 cache is accessed:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/L1CacheExample.png" alt="Selecting an L1 cache set (row)"/></p>
<p>The unit of data in the cache is the <strong>line</strong>, which is just a contiguous chunk of bytes in memory. This cache uses 64-byte lines. The lines are stored in cache banks or <strong>ways</strong>, and each way has a dedicated <strong>directory</strong> to store its housekeeping information. You can imagine each way and its directory as columns in a spreadsheet, in which case the rows are the <em>sets</em>. Then each cell in the way column contains a cache line, tracked by the corresponding cell in the directory. This particular cache has 64 sets and 8 ways, hence 512 cells to store cache lines, which adds up to 32KB of space.</p>
<p>In this cache&#8217;s view of the world, physical memory is divided into 4KB physical pages. Each page has <a href="http://www.google.com/search?hl=en&amp;q=(4KB+/+64+bytes)">4KB / 64 bytes</a> == 64 cache lines in it. When you look at a 4KB page, bytes 0 through 63 within that page are in the first cache line, bytes 64-127 in the second cache line, and so on. The pattern repeats for each page, so the 3rd line in page 0 is different than the 3rd line in page 1.</p>
<p>In a <strong>fully associative cache</strong> any line in memory can be stored in any of the cache cells. This makes storage flexible, but it becomes expensive to search for cells when accessing them. Since the L1 and L2 caches operate under tight constraints of power consumption, physical space, and speed, a fully associative cache is not a good trade off in most scenarios.</p>
<p>Instead, this cache is <strong>set associative</strong>, which means that a given line in memory can only be stored in one specific set (or row) shown above. So the first line of <em>any physical page</em> (bytes 0-63 within a page) <strong>must</strong> be stored in row 0, the second line in row 1, etc. Each row has 8 cells available to store the cache lines it is associated with, making this an 8-way associative set. When looking at a memory address, bits 11-6 determine the line number within the 4KB page and therefore the set to be used. For example, physical address 0x800010a0 has <a href="http://www.google.com/search?q=0x800010a0 in binary">000010</a> in those bits so it must be stored in set 2.</p>
<p>But we still have the problem of finding <em>which</em> cell in the row holds the data, if any. That&#8217;s where the directory comes in. Each cached line is <em>tagged</em> by its corresponding directory cell; the tag is simply the number for the page where the line came from. The processor can address 64GB of physical RAM, so there are <a href="http://www.google.com/search?hl=en&amp;q=lg(64GB+/+4KB)">64GB / 4KB</a> == 2<sup>24</sup> of these pages and thus we need 24 bits for our tag. Our example physical address 0x800010a0 corresponds to page number <a href="http://www.google.com/search?hl=en&amp;q=0x800010a0+Bytes+/+4KB">524,289</a>. Here&#8217;s the second half of the story:</p>
<p align="center"><img src="http://static.duartes.org/img/blogPosts/selectingCacheLine.png" alt="Finding cache line by matching tags"/></p>
<p>Since we only need to look in one set of 8 ways, the tag matching is very fast; in fact, electrically all tags are compared simultaneously, which I tried to show with the arrows. If there&#8217;s a valid cache line with a matching tag, we have a cache hit. Otherwise, the request is forwarded to the L2 cache, and failing that to main system memory. Intel builds large L2 caches by playing with the size and quantity of the ways, but the design is the same. For example, you could turn this into a 64KB cache by adding 8 more ways. Then increase the number of sets to 4096 and each way can store <a href="http://www.google.com/search?hl=en&amp;q=64+Bytes+*+4096">256KB</a>. These two modifications would deliver a 4MB L2 cache. In this scenario, you&#8217;d need 18 bits for the tags and 12 for the set index; the physical page size used by the cache is equal to its way size.</p>
<p>If a set fills up, then a cache line must be evicted before another one can be stored. To avoid this, performance-sensitive programs try to organize their data so that memory accesses are evenly spread among cache lines. For example, suppose a program has an array of 512-byte objects such that some objects are 4KB apart in memory. Fields in these objects fall into the same lines and compete for the same cache set. If the program frequently accesses a given field (<em>e.g.</em>, the <a href="http://en.wikipedia.org/wiki/Vtable">vtable</a> by calling a virtual method), the set will likely fill up and the cache will start trashing as lines are repeatedly evicted and later reloaded. Our example L1 cache can only hold the vtables for 8 of these objects due to set size. This is the cost of the set associativity trade-off: we can get cache misses due to set conflicts even when overall cache usage is not heavy. However, due to the <a href="http://duartes.org/gustavo/blog/what-your-computer-does-while-you-wait">relative speeds</a> in a computer, most apps don&#8217;t need to worry about this anyway.</p>
<p>A memory access usually starts with a linear (virtual) address, so the L1 cache relies on the paging unit to obtain the physical page address used for the cache tags. By contrast, the set index comes from the least significant bits of the linear address and is used without translation (bits 11-6 in our example). Hence the L1 cache is <strong>physically tagged</strong> but <strong>virtually indexed</strong>, helping the CPU to parallelize lookup operations. Because the L1 way is never bigger than an MMU page, a given physical memory location is guaranteed to be associated with the same set even with virtual indexing. L2 caches, on the other hand, must be physically tagged and physically indexed because their way size can be bigger than MMU pages. But then again, by the time a request gets to the L2 cache the physical address was already resolved by the L1 cache, so it works out nicely.</p>
<p>Finally, a directory cell also stores the <em>state</em> of its corresponding cached line. A line in the L1 code cache is either Invalid or Shared (which means valid, really). In the L1 data cache and the L2 cache, a line can be in any of the 4 MESI states: Modified, Exclusive, Shared, or Invalid. Intel caches are <strong>inclusive</strong>: the contents of the L1 cache are duplicated in the L2 cache. These states will play a part in later posts about threading, locking, and that kind of stuff. Next time we&#8217;ll look at the front side bus and how memory access <em>really</em> works. This is going to be memory week.</p>
<p><strong>Update</strong>: <a href="http://www.findinglisp.com/blog/">Dave</a> brought up direct-mapped caches in a <a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches#comment-12687">comment below</a>. They&#8217;re basically a special case of set-associative caches that have only one way. In the trade-off spectrum, they&#8217;re the opposite of fully associative caches: blazing fast access, lots of conflict misses.</p>
<div style="clear:both;"></div>
	 	
		<div class="postmeta">
		
			<div class="postmetaleft">
				<p>January 11, 2009 at 11:11 pm | Filed Under <a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts in Internals" rel="category tag">Internals</a>, <a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts in Software Illustrated" rel="category tag">Software Illustrated</a>				<br /><a class="withImage" href="http://feeds.feedburner.com/GustavoDuarte">
					<img src="http://duartes.org/gustavo/blog/wp-content/themes/Cangaco/images/feed16px.png" alt="Feed Icon" /> 
					<span>Subscribe to blog</span>
				</a></p>
			</div>
			
			<div class="postmetaright">
				<a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches#comments" title="Comment on Cache: a place for concealment and safekeeping">24 Comments</a>&nbsp;			</div>
			
		</div>
			
		<!--
		<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://duartes.org/gustavo/blog/post/intel-cpu-caches"
    dc:identifier="http://duartes.org/gustavo/blog/post/intel-cpu-caches"
    dc:title="Cache: a place for concealment and safekeeping"
    trackback:ping="http://duartes.org/gustavo/blog/post/intel-cpu-caches/trackback" />
</rdf:RDF>		-->
<!-- end write_post -->
		
				<p><a href="http://duartes.org/gustavo/blog/page/2" >Next Page &rarr;</a></p>
	
	</div>
	
<!-- begin r_sidebar -->

	<div id="r_sidebar">
	<ul id="r_sidebarwidgeted">
		
	<li id="Search">
	<h3>Find It</h3>
	   <div class="search">
	   		<form id="searchform" method="get" action="/gustavo/blog/index.php">
			<input type="text" name="s" id="s" value=""/></form>
		</div>
	</li>

	<li id="Recent">
	<h2>Recently Written</h2>
		<ul>
				<li><a href='http://duartes.org/gustavo/blog/post/added-best-of-page-back-to-writing' title='Added Best Of Page, Back to Writing'>Added Best Of Page, Back to Writing</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files' title='Page Cache, the Affair Between Memory and Files'>Page Cache, the Affair Between Memory and Files</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/the-thing-king' title='The Thing King'>The Thing King</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory' title='How The Kernel Manages Your Memory'>How The Kernel Manages Your Memory</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/quick-note-on-diagrams-and-the-blog' title='Quick Note on Diagrams and the Blog'>Quick Note on Diagrams and the Blog</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory' title='Anatomy of a Program in Memory'>Anatomy of a Program in Memory</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/getting-physical-with-memory' title='Getting Physical With Memory'>Getting Physical With Memory</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/programming-and-the-recession' title='Programming and the Recession'>Programming and the Recession</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/daddy-why-does-it-smell-like-fire' title='Daddy, why does it smell like fire?'>Daddy, why does it smell like fire?</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/intel-cpu-caches' title='Cache: a place for concealment and safekeeping'>Cache: a place for concealment and safekeeping</a></li>
		</ul>
	</li>
	
	<li id="Categories">
	<h2>Categories</h2>
		<ul>
			<li class="cat-item cat-item-13"><a href="http://duartes.org/gustavo/blog/category/business" title="View all posts filed under Business">Business</a>
</li>
	<li class="cat-item cat-item-14"><a href="http://duartes.org/gustavo/blog/category/compsci" title="View all posts filed under CompSci">CompSci</a>
</li>
	<li class="cat-item cat-item-11"><a href="http://duartes.org/gustavo/blog/category/culture" title="View all posts filed under Culture">Culture</a>
</li>
	<li class="cat-item cat-item-10"><a href="http://duartes.org/gustavo/blog/category/internals" title="View all posts filed under Internals">Internals</a>
</li>
	<li class="cat-item cat-item-8"><a href="http://duartes.org/gustavo/blog/category/linux" title="View all posts filed under Linux">Linux</a>
</li>
	<li class="cat-item cat-item-7"><a href="http://duartes.org/gustavo/blog/category/meta" title="View all posts filed under Meta">Meta</a>
</li>
	<li class="cat-item cat-item-12"><a href="http://duartes.org/gustavo/blog/category/personal" title="View all posts filed under Personal">Personal</a>
</li>
	<li class="cat-item cat-item-5"><a href="http://duartes.org/gustavo/blog/category/productivity" title="View all posts filed under Productivity">Productivity</a>
</li>
	<li class="cat-item cat-item-3"><a href="http://duartes.org/gustavo/blog/category/programming" title="View all posts filed under Programming">Programming</a>
</li>
	<li class="cat-item cat-item-6"><a href="http://duartes.org/gustavo/blog/category/security" title="View all posts filed under Security">Security</a>
</li>
	<li class="cat-item cat-item-9"><a href="http://duartes.org/gustavo/blog/category/software-illustrated" title="View all posts filed under Software Illustrated">Software Illustrated</a>
</li>
	<li class="cat-item cat-item-4"><a href="http://duartes.org/gustavo/blog/category/sysadmin" title="View all posts filed under Sysadmin">Sysadmin</a>
</li>
		</ul>
	</li>
		
	<li id="Archives">
	<h2>Monthly Archives</h2>
		<ul>
				<li><a href='http://duartes.org/gustavo/blog/post/2010/12' title='December 2010'>December 2010</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2009/02' title='February 2009'>February 2009</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2009/01' title='January 2009'>January 2009</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/12' title='December 2008'>December 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/11' title='November 2008'>November 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/10' title='October 2008'>October 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/08' title='August 2008'>August 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/07' title='July 2008'>July 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/06' title='June 2008'>June 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/05' title='May 2008'>May 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/04' title='April 2008'>April 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/03' title='March 2008'>March 2008</a></li>
	<li><a href='http://duartes.org/gustavo/blog/post/2008/02' title='February 2008'>February 2008</a></li>
		</ul>
	</li>
		
		</ul>
			
</div>

<!-- end r_sidebar -->

</div>

<!-- The main column ends  -->

<div style="clear:both;"></div>


<div id="footerbg">

	<div id="footer">
		<p>Copyright &copy; 2008 <a href="http://duartes.org/gustavo/blog/">Gustavo Duarte</a> &bull; Using Canga&ccedil;o, based on <a href="http://www.briangardner.com/themes/dropshadow-wordpress-theme.htm" >Dropshadow</a> theme by <a href="http://www.briangardner.com" >Brian Gardner</a></p>
	</div>

</div>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-3204790-1");
pageTracker._initData();
pageTracker._trackPageview();
</script>

</body>
</html>

<!-- Dynamic page generated in 0.182 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2013-09-28 14:04:55 -->

<!-- Compression = gzip -->